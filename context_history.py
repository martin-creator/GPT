import os
from tkinter.ttk import Separator
from urllib import response
import openai
import click

# develop a command-line tool that can assist us with Linux commands through conversation.
# Click documentation: https://click.palletsprojects.com/en/8.1.x/


def init_api():
    ''' Load API key from .env file'''
    with open(".env") as env:
        for line in env:
            key, value = line.strip().split("=")
            os.environ[key] = value

    openai.api_key = os.environ["API_KEY"]
    openai.organization = os.environ["ORG_ID"]



# No Context = Chaos of Randomness

# initial_prompt = """You: Hi there!
#     You: Hello!
#     AI: How are you?
#     You: {}
#     AI: """

# while True:
#     prompt = input("You: ")

#     response = openai.Completion.create(
#         engine="text-davinci-003",
#         prompt=initial_prompt.format(prompt),
#         temperature=1,
#         max_tokens=100,
#         stop=[" You", " AI:"]
#     )

#     print("AI:", response["choices"][0]["text"])

# History = Context
# The idea is pretty simple, and it works by creating a history variable where we store the request
# of the user and the text generated by the model. When the user asks a new question, the history is
# inserted before the new question.

# initial_prompt = """You: Hi there!
#     You: Hello!
#     AI: How are you?
#     You: {}
#     AI: """

# history = ""


# while True:
#     prompt = input("You: ")
#     response = openai.Completion.create(
#         engine="text-davinci-003",
#         prompt=initial_prompt.format(history + prompt),
#         temperature=1,
#         max_tokens=100,
#         stop=[" You", " AI:"]
#     )

#     response_text = response["choices"][0]["text"]
#     history += "You: " + prompt + "\n" + "AI: " + response_text + "\n"

#     print("AI:", response_text)

# Last In First Out (LIFO) = Stack
# We create a text file where we will store the history, then we
# store the historical prompts and answers separated by a separator that is not found in the discussion.
# For example: #####
# Then we retrieve the last 2 and add them to the user prompt as a context. Instead of a text file, you
# can use a PostgreSQL database, a Redis database, or whatever you want.

def save_history_to_file(history):
    with open("history.txt", "w+") as file:
        file.write(history)

def load_history_from_file():
    with open("history.txt", "r") as file:
        return file.read()

def get_revelant_history(history):
    history_list = history.split(seperator)
    if len(history_list) > 2:
        return seperator.join(history_list[-2:])
    else:
        return history


init_api()
  

initial_prompt = """You: Hi there!
    You: Hello!
    AI: How are you?
    You: {}
    AI: """

history = ""
seperator = "#####"
relevant_history = ""

while True:
    prompt = input("You: ")
    relevant_history = get_revelant_history(load_history_from_file())

    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=initial_prompt.format(relevant_history + prompt),
        temperature=1,
        max_tokens=100,
        stop=[" You", " AI:"]
    )

    response_text = response["choices"][0]["text"]
    history += "\nYou: " + prompt + "\n" + "AI: " + response_text + "\n" + seperator
    save_history_to_file(history)


    print("AI:", response_text)





